{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "stdout = sys.stdout\n",
    "from imp import reload \n",
    "reload(sys)\n",
    "sys.stdout = stdout\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import pickle as pkl\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "Pre-trained: 26838 (92.18%)\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "# import argparse\n",
    "# parser = argparse.ArgumentParser()\n",
    "# #     parser.add_argument(\"--train\",  help=\"whether to train\", action='store_true')\n",
    "# #     parser.add_argument(\"--test\",  help=\"whether to test\", action='store_true')\n",
    "# args = parser.parse_args()\n",
    "# args.train = True\n",
    "# args.test = False\n",
    "\n",
    "raw_data_path = '../data/WikiQA/raw'\n",
    "processed_data_path = '../data/WikiQA/processed'\n",
    "embedding_path = '../data/embedding/glove.840B.300d.txt'\n",
    "model_path = 'models'\n",
    "\n",
    "with open(os.path.join(processed_data_path, 'vocab.pkl'), 'rb') as fr:\n",
    "    word2id, id2word = pkl.load(fr)\n",
    "max_q_length = 30\n",
    "max_a_length = 100\n",
    "\n",
    "with open(os.path.join(processed_data_path, 'pointwise_corpus.pkl'), 'rb') as fr:\n",
    "    train_corpus, val_corpus, test_corpus = pkl.load(fr)\n",
    "\n",
    "embeddings = build_embedding(embedding_path, word2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qids, train_q, train_aids, train_ap, train_labels = zip(*train_corpus)\n",
    "train_q = padding(train_q, max_q_length)\n",
    "train_ap = padding(train_ap, max_a_length)\n",
    "train_corpus = zip(train_qids, train_q, train_aids, train_ap, train_labels)\n",
    "train_corpus = list(train_corpus)\n",
    "\n",
    "\n",
    "val_qids, val_q, val_aids, val_ap, labels = zip(*val_corpus)\n",
    "val_q = padding(val_q, max_q_length)\n",
    "val_ap = padding(val_ap, max_a_length)\n",
    "val_corpus = zip(val_qids, val_q, val_aids, val_ap, labels)\n",
    "val_corpus = list(val_corpus)\n",
    "\n",
    "\n",
    "test_qids, test_q, test_aids, test_ap, labels = zip(*test_corpus)\n",
    "test_q = padding(test_q, max_q_length)\n",
    "test_ap = padding(test_ap, max_a_length)\n",
    "test_corpus = zip(test_qids, test_q, test_aids, test_ap, labels)\n",
    "test_corpus = list(test_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "nn method is not implemented!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-668ce61bd62d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_a_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_a_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m#     if args.train:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;31m#     elif args.test:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m#         test(test_corpus, config)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-668ce61bd62d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_corpus, config, val_corpus, eval_train_corpus)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeqMatchSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Question_Answering_Models/cQA/seq_match_seq/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mh_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_encode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_encode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# compose层\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_encode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# aggregate层\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0magg_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Question_Answering_Models/cQA/seq_match_seq/models.py\u001b[0m in \u001b[0;36mcompare\u001b[0;34m(self, a, h_a)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0ma_ha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma_ha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             raise ValueError('{} method is not implemented!'.format(\n",
      "\u001b[0;31mValueError\u001b[0m: nn method is not implemented!"
     ]
    }
   ],
   "source": [
    "from models import SeqMatchSeq\n",
    "tf.reset_default_graph()\n",
    "def train(train_corpus, config, val_corpus, eval_train_corpus=None):\n",
    "    iterator = Iterator(train_corpus)\n",
    "\n",
    "    with tf.Session(config=config.cf) as sess:\n",
    "        model = SeqMatchSeq(config)\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(config.num_epochs):\n",
    "            count = 0\n",
    "            for batch_x in iterator.next(config.batch_size, shuffle=True):\n",
    "                batch_qids, batch_q, batch_aids, batch_ap, labels = zip(*batch_x)\n",
    "                batch_q = np.asarray(batch_q)\n",
    "                batch_ap = np.asarray(batch_ap)\n",
    "                labels = np.asarray(labels).astype(np.int32)\n",
    "                _, loss = sess.run([model.train_op, model.total_loss], \n",
    "                                   feed_dict={model.q:batch_q, \n",
    "                                              model.a:batch_ap,\n",
    "                                              model.y:labels,\n",
    "                                              model.keep_prob:config.keep_prob})\n",
    "                count += 1\n",
    "                if count % 10 == 0:\n",
    "                    print('[epoch {}, batch {}]Loss:{}'.format(epoch, count, loss))\n",
    "            saver.save(sess,'{}/my_model'.format(model_path), global_step=epoch)\n",
    "            if eval_train_corpus is not None:\n",
    "                train_res = evaluate(sess, model, eval_train_corpus, config)\n",
    "                print('[train] ' + train_res)\n",
    "            if val_corpus is not None:\n",
    "                val_res = evaluate(sess, model, val_corpus, config)\n",
    "                print('[eval] ' + val_res)\n",
    "\n",
    "\n",
    "def evaluate(sess, model, corpus, config):\n",
    "    iterator = Iterator(corpus)\n",
    "\n",
    "    count = 0\n",
    "    total_qids = []\n",
    "    total_aids = []\n",
    "    total_pred = []\n",
    "    total_labels = []\n",
    "    total_loss = 0.\n",
    "    for batch_x in iterator.next(config.batch_size, shuffle=False):\n",
    "        batch_qids, batch_q, batch_aids, batch_ap, labels = zip(*batch_x)\n",
    "        batch_q = np.asarray(batch_q)\n",
    "        batch_ap = np.asarray(batch_ap)\n",
    "        y_hat, loss = sess.run([model.y_hat, model.total_loss], \n",
    "                           feed_dict={model.q:batch_q, \n",
    "                                      model.a:batch_ap, \n",
    "                                      model.y:labels,\n",
    "                                      model.keep_prob:1.})\n",
    "        y_hat = np.argmax(y_hat, axis=-1)\n",
    "        total_loss += loss\n",
    "        count += 1\n",
    "        total_qids.append(batch_qids)\n",
    "        total_aids.append(batch_aids)\n",
    "        total_pred.append(y_hat)\n",
    "        total_labels.append(labels)\n",
    "        # print(batch_qids[0], [id2word[_] for _ in batch_q[0]], \n",
    "        #     batch_aids[0], [id2word[_] for _ in batch_ap[0]])\n",
    "    total_qids = np.concatenate(total_qids, axis=0)\n",
    "    total_aids = np.concatenate(total_aids, axis=0)\n",
    "    total_pred = np.concatenate(total_pred, axis=0)\n",
    "    total_labels = np.concatenate(total_labels, axis=0)\n",
    "    MAP, MRR = eval_map_mrr(total_qids, total_aids, total_pred, total_labels)\n",
    "    # print('Eval loss:{}'.format(total_loss / count))\n",
    "    return 'MAP:{}, MRR:{}'.format(MAP, MRR)\n",
    "                \n",
    "\n",
    "def test(corpus, config):\n",
    "    with tf.Session(config=config.cf) as sess:\n",
    "        model = SeqMatchSeq(config)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(model_path))\n",
    "        print('[test] ' + evaluate(sess, model, corpus, config))\n",
    "        \n",
    "\n",
    "class SeqMatchSeqConfig(object):\n",
    "    def __init__(self, vocab_size, comp_type='mul', embeddings=None):\n",
    "        # 输入问题(句子)长度\n",
    "        self.max_q_length = 200\n",
    "        # 输入答案长度\n",
    "        self.max_a_length = 200\n",
    "        # 循环数\n",
    "        self.num_epochs = 5\n",
    "        # batch大小\n",
    "        self.batch_size = 128\n",
    "        # 词表大小\n",
    "        self.vocab_size = vocab_size\n",
    "        # 词向量大小\n",
    "        self.embeddings = embeddings\n",
    "        self.embedding_size = 300\n",
    "        if self.embeddings is not None:\n",
    "            self.embedding_size = embeddings.shape[1]\n",
    "        # keep_prob=1-dropout\n",
    "        self.keep_prob = 0.6\n",
    "        # 学习率\n",
    "        self.lr = 0.0003\n",
    "        self.grad_clip = 1\n",
    "\n",
    "        self.reg = 0\n",
    "        self.mem_dim = 128\n",
    "        self.cov_dim = 128\n",
    "        self.filter_sizes = [2, 3, 4, 5]\n",
    "        self.comp_type = comp_type\n",
    "\n",
    "        self.cf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "        self.cf.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "        \n",
    "config = SeqMatchSeqConfig(max(word2id.values()) + 1, comp_type='nn', embeddings=embeddings)\n",
    "config.max_q_length = max_q_length\n",
    "config.max_a_length = max_a_length\n",
    "#     if args.train:\n",
    "train(deepcopy(train_corpus), config, val_corpus, deepcopy(train_corpus))\n",
    "#     elif args.test:\n",
    "#         test(test_corpus, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
